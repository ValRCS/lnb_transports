{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a873db04",
   "metadata": {},
   "source": [
    "# Visualize terms document frequency, term frequency, and relative frequency over time\n",
    "\n",
    "## Custom translations and colors for original terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6029805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a dictionary of translations for all the keys from Latvian to English\n",
    "# original_terms_translations = {\n",
    "#     \"auto\": \"car\",\t\n",
    "#     \"autobuss\": \"bus\",\n",
    "#     \"automobilis\": \"automobile\",\n",
    "#     \"divjūgs\": \"pair carriage\",\n",
    "#     \"divritenis\": \"bicycle\",\n",
    "#     \"droška\": \"droshky\",\n",
    "#     \"dzelzceļš\": \"railway\",\n",
    "#     \"fūrmanis\": \"hired waggoner\",\n",
    "#     \"kamanas\": \"sleigh\",\n",
    "#     \"kariete\": \"coach\",\n",
    "#     \"linijdroška\": \"line droshky\",\n",
    "#     \"mašīna\": \"machine\",\n",
    "#     \"motocikls\": \"motorcycle\",\n",
    "#     \"ore\": \"farm wagon\",\n",
    "#     \"ormanis\": \"horse-drawn cab\",\n",
    "#     \"pajūgs\": \"rig\",\n",
    "#     \"ragavas\": \"sledge\",\n",
    "#     # \"rati\": \"carriage\",\n",
    "#     \"taksometrs\": \"taxi\",\n",
    "#     \"tramvajs\": \"tram\",\n",
    "#     \"velosipēds\": \"velocipede\",\n",
    "#     \"vezums\": \"wagon\",\n",
    "#     \"važonis\": \"coachman\",\n",
    "# }\n",
    "# # how many keys\n",
    "# print(f\"original_terms_translations keys: {len(original_terms_translations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835790b",
   "metadata": {},
   "source": [
    "## Loading Libraries and showing hardware used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e40716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]\n",
      "Run date: 2025-05-29 12:04:48.327600\n",
      "Project root: C:\\Users\\vsaules\\Github\\lnb_transports\n",
      "Computer name: 11P00694\n",
      "CPU architecture: AMD64\n",
      "CPU type Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\n",
      "CPU count: 8\n",
      "OS name: Windows\n",
      "OS version: 10.0.19045\n",
      "Memory: 31.80 GB : free - 21.87 GB\n",
      "Swap memory: 4.75 GB : free - 4.30 GB\n",
      "Disk space: 222.96 GB : free - 53.74 GB\n",
      "EXTERNAL libraries\n",
      "tqdm version: 4.66.2\n",
      "Pandas version: 2.2.1\n",
      "Plotly version: 5.19.0\n"
     ]
    }
   ],
   "source": [
    "# Show Python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "from datetime import datetime\n",
    "print(f\"Run date: {datetime.now()}\")\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Get the project root by going one level up from the current notebook directory\n",
    "project_root = Path().resolve().parent\n",
    "print(f\"Project root: {project_root}\")\n",
    "# what computer are we on?\n",
    "import socket\n",
    "print(f\"Computer name: {socket.gethostname()}\")\n",
    "# CPU architecture\n",
    "import platform\n",
    "print(f\"CPU architecture: {platform.machine()}\")\n",
    "# CPU type\n",
    "print(f\"CPU type {platform.processor()}\")\n",
    "# CPU count\n",
    "print(f\"CPU count: {os.cpu_count()}\")\n",
    "# OS name and version\n",
    "print(f\"OS name: {platform.system()}\")\n",
    "print(f\"OS version: {platform.version()}\")\n",
    "# memory and disk space\n",
    "import psutil\n",
    "print(f\"Memory: {psutil.virtual_memory().total / (1024 ** 3):.2f} GB : free - {psutil.virtual_memory().available / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Swap memory: {psutil.swap_memory().total / (1024 ** 3):.2f} GB : free - {psutil.swap_memory().free / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Disk space: {psutil.disk_usage('/').total / (1024 ** 3):.2f} GB : free - {psutil.disk_usage('/').free / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "# try importing the libraries we need\n",
    "print(\"EXTERNAL libraries\")\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    from tqdm import __version__ as tqdm_version\n",
    "    print(f\"tqdm version: {tqdm_version}\")\n",
    "except ImportError:\n",
    "    print(\"tqdm not installed\")\n",
    "    print(\"Please install tqdm with 'pip install tqdm'\")\n",
    "\n",
    "#Pandas\n",
    "try:\n",
    "    import pandas as pd\n",
    "    from pandas import __version__ as pandas_version\n",
    "    print(f\"Pandas version: {pandas_version}\")\n",
    "except ImportError:\n",
    "    print(\"Pandas not installed\")\n",
    "    print(\"\"\"Please install pandas with 'pip install \"pandas[excel,parquet]\"'\"\"\")\n",
    "\n",
    "# now plotly\n",
    "try:\n",
    "    from plotly import express as px\n",
    "    from plotly import graph_objects as go\n",
    "    from plotly import __version__ as plotly_version\n",
    "    print(f\"Plotly version: {plotly_version}\")\n",
    "except ImportError:\n",
    "    print(\"Plotly not installed\")\n",
    "    print(\"Please install plotly with 'pip install plotly'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1229c2f2",
   "metadata": {},
   "source": [
    "## Loading Main Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a956dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = Path(\"../../not_repo/latsenrom_2025_05_09.parquet\")\n",
    "\n",
    "# # assert src.exists()\n",
    "# assert src.is_file(), f\"File not found: {src}\"\n",
    "# # loading\n",
    "# print(f\"Loading from {src}\")\n",
    "# df = pd.read_parquet(src)\n",
    "# # check the dataframe\n",
    "# # shape\n",
    "# print(f\"df.shape: {df.shape}\")\n",
    "# # head\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01962b77",
   "metadata": {},
   "source": [
    "## Loading moto and horse terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263de2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# horse_moto_file = Path(\"../csv/Sauszemes-transporta-termini.csv\")\n",
    "# # assert horse_moto_file.exists()\n",
    "# assert horse_moto_file.is_file(), f\"File not found: {horse_moto_file}\"\n",
    "# horse_moto_df = pd.read_csv(horse_moto_file, sep=\";\")\n",
    "# # check the dataframe\n",
    "# # shape\n",
    "# print(f\"horse_moto_df.shape: {horse_moto_df.shape}\")\n",
    "# # head\n",
    "# horse_moto_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d180e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's change column names\n",
    "# # Word will be ngram, and Zirgu / Moto transporta termini will be horse_moto\n",
    "# horse_moto_df.rename(columns={\n",
    "#     \"Zirgu / Motorizēts\": \"horse_moto\",\n",
    "#     \"Word\": \"ngram\"\n",
    "# }, inplace=True)\n",
    "# # head now\n",
    "# horse_moto_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fd910db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's do value counts for horse_moto\n",
    "# horse_moto_counts = horse_moto_df['horse_moto'].value_counts()\n",
    "# # print the counts\n",
    "# print(\"Horse / Moto transport terms counts:\")\n",
    "# print(horse_moto_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ad83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's make a function that creates tuple of terms from ngram\n",
    "# the logic will be as follows we split by whitespace unless the ngram contains period then we keep it as a single term\n",
    "# def create_terms_tuple(ngram):\n",
    "#     # split by whitespace unless the ngram contains period\n",
    "#     if \".\" in ngram:\n",
    "#         return (ngram,)\n",
    "#     else:\n",
    "#         return tuple(ngram.split())\n",
    "    \n",
    "# # now let's creat a new column with the terms tuple\n",
    "# horse_moto_df[\"terms_tuple\"] = horse_moto_df[\"ngram\"].apply(create_terms_tuple)\n",
    "# # shape\n",
    "# print(f\"horse_moto_df.shape after adding terms_tuple: {horse_moto_df.shape}\")\n",
    "# # head\n",
    "# horse_moto_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2054da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's rename the column to lemma_tuple\n",
    "# horse_moto_df.rename(columns={\"terms_tuple\": \"lemma_tuple\"}, inplace=True)\n",
    "# # head now\n",
    "# horse_moto_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb55700",
   "metadata": {},
   "source": [
    "## Cleaning out Zero occurance terms\n",
    "\n",
    "Due to differences between NoSketch tagger for Vert and NLP-PIPE tagger we have some differences in terms which we have to clean semi manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95042c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's go through ngram tuples one by one and count how many times they appear in corpus in df dataframe\n",
    "# we will use df.lemma column for that\n",
    "# the extra difficulty is that lemma contains single words but we could have multiple sequential words in ngram\n",
    "\n",
    "# our first approach will involve creating a single mega string from all lemma by joining them with whitespace\n",
    "# mega_string = \" \".join(df[\"lemma\"].astype(str).tolist())\n",
    "# # how long is the mega string?\n",
    "# print(f\"Length of mega_string: {len(mega_string)} characters\")\n",
    "# # how many uppercase letters?\n",
    "# uppercase_count = sum(1 for c in mega_string if c.isupper())\n",
    "# print(f\"Uppercase letters in mega_string: {uppercase_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a29c6d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase the mega string\n",
    "# mega_string = mega_string.lower()\n",
    "# how many lowercase letters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db884be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can count how many times each ngram appears in the mega string\n",
    "# def count_ngram_in_mega_string(ngram, text):\n",
    "#     return text.count(ngram)\n",
    "\n",
    "# # let's test it on first ngram\n",
    "# first_ngram = horse_moto_df[\"ngram\"].iloc[0]\n",
    "# print(f\"First ngram: {first_ngram}\")\n",
    "# # count how many times it appears in mega_string\n",
    "# count = count_ngram_in_mega_string(first_ngram, mega_string)\n",
    "# print(f\"Count of first ngram '{first_ngram}' in mega_string: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a627ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how about 4 more ngrams?\n",
    "# for i in range(1, 5):\n",
    "#     ngram = horse_moto_df[\"ngram\"].iloc[i]\n",
    "#     count = count_ngram_in_mega_string(ngram, mega_string)\n",
    "#     print(f\"Count of ngram '{ngram}' in mega_string: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d13daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find 20 characters before and after each instance of term \"romeo\"\n",
    "def find_term_context(term, text, context_length=20):\n",
    "    indices = []\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = text.find(term, start)\n",
    "        if start == -1:\n",
    "            break\n",
    "        indices.append(start)\n",
    "        start += len(term)  # move past the current term\n",
    "    contexts = []\n",
    "    for index in indices:\n",
    "        start_index = max(0, index - context_length)\n",
    "        end_index = min(len(text), index + len(term) + context_length)\n",
    "        contexts.append(text[start_index:end_index])\n",
    "    return contexts\n",
    "\n",
    "# # let's test it on romeo\n",
    "# term = \"Romeo\"\n",
    "# contexts = find_term_context(term, mega_string)\n",
    "# # how many contexts we found?\n",
    "# print(f\"Found {len(contexts)} contexts for term '{term}'\")\n",
    "# # print the first 5 contexts\n",
    "# for i, context in enumerate(contexts[:5]):\n",
    "#     print(f\"Context {i+1}: {context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0827fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a new column ngram_count in horse_moto_df that will contain the count of each ngram in mega_string\n",
    "# horse_moto_df[\"ngram_count\"] = horse_moto_df[\"ngram\"].apply(lambda x: count_ngram_in_mega_string(x.lower(), mega_string))\n",
    "# # show the first 20 rows\n",
    "# horse_moto_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "163dea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's save the horse_moto_df to xlsx file\n",
    "# output_file = Path(\"../xlsx/sauszemes_transporta_termini.xlsx\")\n",
    "# # save to xlsx\n",
    "# horse_moto_df.to_excel(output_file, index=False)\n",
    "# # show the output file path\n",
    "# print(f\"Saved horse_moto_df to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ea34b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show which ngrams have count 0\n",
    "# zero_count_df = horse_moto_df[horse_moto_df[\"ngram_count\"] == 0]\n",
    "# # shape of zero_count_df\n",
    "# print(f\"zero_count_df shape: {zero_count_df.shape}\")\n",
    "# # show the first 20 rows of zero_count_df\n",
    "# zero_count_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33dba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d57a44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"šībervilcien\" in mega_string\n",
    "# # find contexts for \"šībervilcien\"\n",
    "# contexts = find_term_context(\"šībervilcien\", mega_string, context_length=50)\n",
    "# # print the first 5 contexts\n",
    "# for i, context in enumerate(contexts[:5]):\n",
    "#     print(f\"Context {i+1}: {context}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63a53b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's save zero_count_df to xlsx file\n",
    "# zero_count_output_file = Path(\"../xlsx/sauszemes_transporta_termini_zero_count.xlsx\")   \n",
    "# zero_count_df.to_excel(zero_count_output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b45540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's check kurvjrat\n",
    "# kurvjrat = \"kurvjrat\"\n",
    "# # find contexts for \"kurvjrat\"\n",
    "# contexts = find_term_context(kurvjrat, mega_string, context_length=50)\n",
    "# # how many contexts we found?\n",
    "# print(f\"Found {len(contexts)} contexts for term '{kurvjrat}'\")\n",
    "# # print the first 5 contexts\n",
    "# for i, context in enumerate(contexts[:5]):\n",
    "#     print(f\"Context {i+1}: {context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9a43f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a function that will take a term and mega_string and return contexts\n",
    "# it will also print how many contexts were found and by default will print the first 5 contexts\n",
    "# def print_term_contexts(term, text, context_length=50, max_print=5):\n",
    "#     contexts = find_term_context(term, text, context_length)\n",
    "#     print(f\"Found {len(contexts)} contexts for term '{term}'\")\n",
    "#     for i, context in enumerate(contexts[:max_print]):\n",
    "#         print(f\"Context {i+1}: {context}\")\n",
    "# let's test it on \"kurvjrat\"\n",
    "#print_term_contexts(\"autovāģ\", mega_string, context_length=50, max_print=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e3b200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now ātrs palīdzība rat\n",
    "#print_term_contexts(\"ātrs palīdzība rat\", mega_string, context_length=50, max_print=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11c9a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now bagažas vilcien\n",
    "#print_term_contexts(\"bagaža vilcien\", mega_string, context_length=50, max_print=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8ef0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now goda-rat\n",
    "#print_term_contexts(\"gods rats\", mega_string, context_length=50, max_print=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dba8320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_ngrams = zero_count_df[\"ngram\"].tolist()\n",
    "# print(f\"Number of zero count ngrams: {len(zero_ngrams)}\")\n",
    "# print(f\"Those are: {zero_ngrams}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7587f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find dzelzsceļs rati\n",
    "# print_term_contexts(\"dzelzceļš rats\", mega_string, context_length=50, max_print=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "647383a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now essex\n",
    "# print_term_contexts(\"essex\", mega_string, context_length=50, max_print=15)\n",
    "# # roadster\n",
    "# print_term_contexts(\"roadster\", mega_string, context_length=50, max_print=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "909c89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now kamanas\n",
    "# print_term_contexts(\"kamanas\", mega_string, context_length=50, max_print=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c94d7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use regex to find kamanas where previous word starts with f\n",
    "# import re\n",
    "# def find_kamanas_with_previous_f(text):\n",
    "#     pattern = r'f\\S+\\s+kamanas'\n",
    "#     matches = re.findall(pattern, text)\n",
    "#     return matches  \n",
    "# # let's find kamanas with previous word starting with f\n",
    "# matches = find_kamanas_with_previous_f(mega_string)\n",
    "# print(f\"Found {len(matches)} matches for 'kamanas' with previous word starting with 'f'\")\n",
    "# # print all matches\n",
    "# for i, match in enumerate(matches):\n",
    "#     print(f\"Match {i+1}: {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6dcbbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a generic function that will return all matches given text, needle and previous word pattern\n",
    "# def find_matches_with_previous_word(text, needle, previous_word_pattern):\n",
    "#     pattern = rf'{previous_word_pattern}\\S+\\s+{needle}'\n",
    "#     matches = re.findall(pattern, text)\n",
    "#     return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a6b85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first print context for Davidsons\n",
    "# print_term_contexts(\"davidsons\", mega_string, context_length=50, max_print=15)\n",
    "# # how about harley\n",
    "# print_term_contexts(\"harley\", mega_string, context_length=50, max_print=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c11724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now context for motorrats\n",
    "# print_term_contexts(\"motorrats\", mega_string, context_length=50, max_print=15)\n",
    "# # how about motorrati\n",
    "# print_term_contexts(\"motorrati\", mega_string, context_length=50, max_print=15)\n",
    "# # motorats\n",
    "# print_term_contexts(\"motorats\", mega_string, context_length=50, max_print=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c2645f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now try redelains \n",
    "# print_term_contexts(\"redelains\", mega_string, context_length=50, max_print=15)\n",
    "# # how about redelain\n",
    "# print_term_contexts(\"redelain\", mega_string, context_length=50, max_print=15)\n",
    "# # redela\n",
    "# print_term_contexts(\"redela\", mega_string, context_length=50, max_print=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c31bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now \"roll-rois\"\n",
    "# print_term_contexts(\"roll-rois\", mega_string, context_length=50, max_print=15)\n",
    "# # how about just roll\n",
    "# print_term_contexts(\"roll\", mega_string, context_length=50, max_print=15)\n",
    "# # hmm how about just rois\n",
    "# print_term_contexts(\"rois\", mega_string, context_length=50, max_print=15)\n",
    "# # now rol-rois\n",
    "# print_term_contexts(\"rol-rois\", mega_string, context_length=50, max_print=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6e59e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now finally sanitars\n",
    "# print_term_contexts(\"sanitars\", mega_string, context_length=50, max_print=15)\n",
    "# how about automobil where word previous to it starts with s\n",
    "# matches = find_matches_with_previous_word(mega_string, \"automobil\", r'san\\S+')\n",
    "# print(f\"Found {len(matches)} matches for 'automobil' with previous word starting with 's'\")\n",
    "# # print all matches\n",
    "# for i, match in enumerate(matches):\n",
    "#     print(f\"Match {i+1}: {match}\")\n",
    "# # now let's try context for sanitārs automobil\n",
    "# print_term_contexts(\"sanitārs automobil\", mega_string, context_length=50, max_print=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d3dd9",
   "metadata": {},
   "source": [
    "## Separating horse_mote into horse and moto terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da4573ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# horse_moto_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b35774f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's create separate lists of terms that are moto and horse\n",
    "# moto_terms = horse_moto_df[horse_moto_df[\"horse_moto\"] == \"m\"][\"ngram\"].tolist()\n",
    "# horse_terms = horse_moto_df[horse_moto_df[\"horse_moto\"] == \"z\"][\"ngram\"].tolist()\n",
    "# # how many motto terms we have?\n",
    "# print(f\"Number of moto terms: {len(moto_terms)}\")\n",
    "# print(f\"Number of horse terms: {len(horse_terms)}\")\n",
    "# # how many total terms we have?\n",
    "# total_terms = len(moto_terms) + len(horse_terms)\n",
    "# print(f\"Total terms: {total_terms}\")\n",
    "# # assert number is equal to horse_moto_df shape\n",
    "# assert total_terms == horse_moto_df.shape[0], f\"Total terms {total_terms} does not match horse_moto_df shape {horse_moto_df.shape[0]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67d864",
   "metadata": {},
   "source": [
    "## Create lower case lemma texts for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39200395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will create a dictionary where key will be unique file_stem_short + firstEdition\n",
    "# value will be lowercase lemma joined by whitespace\n",
    "# we can actually do this using pandas using group by and then aggregate\n",
    "# let's create a new column with file_stem_short + firstEdition\n",
    "# df[\"file_stem_short_firstEdition\"] = df[\"file_stem_short\"] + \"_\" + df[\"firstEdition\"].astype(str)\n",
    "# # how many unique file_stem_short_firstEdition we have?\n",
    "# unique_file_stem_firstEdition_count = df[\"file_stem_short_firstEdition\"].nunique()\n",
    "# print(f\"Unique file_stem_short_firstEdition count: {unique_file_stem_firstEdition_count}\")\n",
    "# # TODO why is count 470 when korpuss.lnb.lv shows 458 ?\n",
    "# # TODO create set difference between korpuss.lnb.lv and our dataframe\n",
    "# # assert that it is equal to the number of unique file_stem_short\n",
    "# unique_file_stem_count = df[\"file_stem_short\"].nunique()\n",
    "# print(f\"Unique file_stem_short count: {unique_file_stem_count}\")\n",
    "# assert unique_file_stem_firstEdition_count == unique_file_stem_count, \\\n",
    "#     f\"Unique file_stem_short_firstEdition count {unique_file_stem_firstEdition_count} does not match unique file_stem_short count {unique_file_stem_count}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "043df3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # which file_stem_short have more than one firstEdition?\n",
    "# multiple_firstEdition = df.groupby(\"file_stem_short\")[\"firstEdition\"].nunique()\n",
    "# multiple_firstEdition = multiple_firstEdition[multiple_firstEdition > 1]\n",
    "# print(f\"File stems with multiple first editions: {len(multiple_firstEdition)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f701684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple_firstEdition.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40745ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the years for those with multiple first editions\n",
    "# for file_stem, editions in multiple_firstEdition.items():\n",
    "#     years = df[df[\"file_stem_short\"] == file_stem][\"firstEdition\"].unique()\n",
    "#     print(f\"{file_stem}: {years}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0109678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so let's add years later and just use file_stem_short for now\n",
    "# we will group by file_stem_short and aggregate lemma using whitespace join then lowercase it\n",
    "# df_grouped = df.groupby(\"file_stem_short\")[\"lemma\"].apply(lambda x: \" \".join(x).lower()).reset_index()\n",
    "# # rename the column to lemma_joined\n",
    "# df_grouped.rename(columns={\"lemma\": \"lemma_joined\"}, inplace=True)\n",
    "# # index name to file_stem_short\n",
    "# df_grouped.set_index(\"file_stem_short\", inplace=True)\n",
    "# # now we have a dataframe with file_stem_short as index and lemma_joined as column\n",
    "# # shape of df_grouped\n",
    "# print(f\"df_grouped shape: {df_grouped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e52b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b6eb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's add year column to df_grouped\n",
    "# # we will use the min firstEdition for each file_stem_short\n",
    "# df_grouped[\"year\"] = df.groupby(\"file_stem_short\")[\"firstEdition\"].min().values\n",
    "# # now we have a dataframe with file_stem_short as index, lemma_joined and year as columns\n",
    "# # shape of df_grouped after adding year\n",
    "# print(f\"df_grouped shape after adding year: {df_grouped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59148274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's see which keys have year 1879 ?\n",
    "# keys_1879 = df_grouped[df_grouped[\"year\"] == 1879].index.tolist()\n",
    "# print(f\"Keys with year 1879: {len(keys_1879)}\")\n",
    "# # print the first 10 keys with year 1879\n",
    "# for key in keys_1879[:10]:\n",
    "#     print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5c1081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's look for term auto in the lemma_joined column for KaudR_MernL\n",
    "# kaudr_mern_l = df_grouped.loc[\"KaudR_MernL\", \"lemma_joined\"]\n",
    "# find_term_context(\"auto\", kaudr_mern_l, context_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6116098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how about  \" auto \" ?\n",
    "# find_term_context(\" auto \", kaudr_mern_l, context_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5110875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaudr_mern_l.count(\"auto\"), kaudr_mern_l.count(\" auto \"), kaudr_mern_l.count(\"auto \"), kaudr_mern_l.count(\" auto\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57156c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's see year for index DambV_GaitC\n",
    "# print(f\"Year for index 'DambV_GaitC': {df_grouped.loc['DambV_GaitC', 'year']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c024c36",
   "metadata": {},
   "source": [
    "## Saving and Loading lemma texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bc9fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's save this df_grouped to a parquet file\n",
    "# output_grouped_file = Path(\"../../not_repo/latsenrom_file_stem_short_grouped_lemma_lowercase.parquet\")\n",
    "# # df_grouped.to_parquet(output_grouped_file)\n",
    "# # print(f\"Saved df_grouped to {output_grouped_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce434de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading the grouped dataframe from parquet file\n",
    "# df_grouped_loaded = pd.read_parquet(output_grouped_file)\n",
    "# # # assert df_grouped_loaded.shape == df_grouped.shape, \\\n",
    "# # #     f\"Loaded df_grouped shape {df_grouped_loaded.shape} does not match original df_grouped shape {df_grouped.shape}\"\n",
    "# # # # it is safe to now use alias df_grouped_loaded as df_grouped\n",
    "# df_grouped = df_grouped_loaded\n",
    "# print(\"Loaded df_grouped from parquet file {output_grouped_file} successfully.\")\n",
    "# # shape of loaded dataframe\n",
    "# print(f\"Loaded df_grouped shape: {df_grouped.shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7237d",
   "metadata": {},
   "source": [
    "## Counting absolute and relative frequencies in invidual works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "170ad834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have plaintexts for each file stem short and we have moto and horse terms\n",
    "# we can count each term in each file stem short\n",
    "# we will create a new dictionary where key will be file_stem_short and value will be another dictionary\n",
    "# this inner dictionary will contain year and counts for each term\n",
    "# let's create a function that will do that\n",
    "# def count_terms_in_file_stems(df_grouped, terms, pad_whitespace=True):\n",
    "#     counts_dict = {}\n",
    "#     # if pad_whitespace is True, we will pad terms with whitespace on both sides\n",
    "#     if pad_whitespace: # we use strip first since some terms might already have whitespace\n",
    "#         terms = [f\" {term.strip()} \".lower() for term in terms]  # pad with whitespace\n",
    "#     else:\n",
    "#         terms = [term.lower() for term in terms]  # just lowercase the terms    \n",
    "#     for file_stem in tqdm(df_grouped.index):\n",
    "#         # get the lemma_joined for this file_stem\n",
    "#         lemma_joined = df_grouped.loc[file_stem, \"lemma_joined\"]\n",
    "#         # pad whitespace if needed\n",
    "#         if pad_whitespace: # this will let us match terms in beginning and end of text\n",
    "#             lemma_joined = f\" {lemma_joined.strip()} \"\n",
    "#         # create a dictionary to hold counts for this file_stem\n",
    "#         # we strip the terms to avoid issues with leading/trailing whitespace\n",
    "#         counts = {term.strip(): lemma_joined.count(term) for term in terms}\n",
    "#         # add year\n",
    "#         counts[\"year\"] = df_grouped.loc[file_stem, \"year\"]\n",
    "#         # add to the main dictionary\n",
    "#         counts_dict[file_stem] = counts\n",
    "#     return counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63310143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create moto_dict and horse_dict\n",
    "# print(f\"Current date and time: {datetime.now()}\")\n",
    "# print(\"Creating moto_dict and horse_dict...\")\n",
    "# moto_dict = count_terms_in_file_stems(df_grouped_loaded, moto_terms)    \n",
    "# horse_dict = count_terms_in_file_stems(df_grouped_loaded, horse_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96b7299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create two new dataframes from these dictionaries\n",
    "# moto_df = pd.DataFrame.from_dict(moto_dict, orient='index')\n",
    "# # we want year column to be first column right after index\n",
    "# moto_df.reset_index(inplace=True)\n",
    "# moto_df.rename(columns={\"index\": \"file_stem_short\"}, inplace=True)\n",
    "# # reorder columns to have year first\n",
    "# moto_df = moto_df[[\"file_stem_short\", \"year\"] + [col for col in moto_df.columns if col not in [\"file_stem_short\", \"year\"]]]\n",
    "# # shape of moto_df\n",
    "# print(f\"moto_df shape: {moto_df.shape}\")\n",
    "# # head of moto_df\n",
    "# moto_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2cbb8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's do the same for horse_dict\n",
    "# horse_df = pd.DataFrame.from_dict(horse_dict, orient='index')\n",
    "# # we want year column to be first column right after index\n",
    "# horse_df.reset_index(inplace=True)\n",
    "# horse_df.rename(columns={\"index\": \"file_stem_short\"}, inplace=True)\n",
    "# # reorder columns to have year first\n",
    "# horse_df = horse_df[[\"file_stem_short\", \"year\"] + [col for col in horse_df.columns if col not in [\"file_stem_short\", \"year\"]]]\n",
    "# # shape of horse_df\n",
    "# print(f\"horse_df shape: {horse_df.shape}\")\n",
    "# # head of horse_df\n",
    "# horse_df.head()# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4941f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # before saving let's check if any columns have all zeros\n",
    "# def check_zero_columns(df):\n",
    "#     zero_columns = [col for col in df.columns if df[col].sum() == 0]\n",
    "#     return zero_columns\n",
    "# # # # check zero columns in moto_df\n",
    "# zero_columns_moto = check_zero_columns(moto_df)\n",
    "# print(f\"Zero columns in moto_df: {zero_columns_moto}\")\n",
    "# # check zero columns in horse_df\n",
    "# zero_columns_horse = check_zero_columns(horse_df)\n",
    "# print(f\"Zero columns in horse_df: {zero_columns_horse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5daf7",
   "metadata": {},
   "source": [
    "### Special case for auto before 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ceba4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there is no real use of auto before 1920\n",
    "# how many auto terms we have before 1920?\n",
    "# print(f'We have { moto_df.loc[moto_df[\"year\"] < 1920, \"auto\"].sum() } auto terms before 1920.')\n",
    "# # we have to mark all auto usage as 0 before 1920\n",
    "# moto_df.loc[moto_df[\"year\"] < 1920, \"auto\"] = 0\n",
    "# # now how many auto terms we have before 1920?\n",
    "# print(f'We have { moto_df.loc[moto_df[\"year\"] < 1920, \"auto\"].sum() } auto terms before 1920 after setting to 0.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11783e",
   "metadata": {},
   "source": [
    "### Saving and loading term frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71b1dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's save these dataframes to parquet files\n",
    "# output_moto_file = Path(\"../parquet/latsenrom_moto_terms_counts.parquet\")\n",
    "# output_horse_file = Path(\"../parquet/latsenrom_horse_terms_counts.parquet\")\n",
    "# moto_df.to_parquet(output_moto_file)\n",
    "# horse_df.to_parquet(output_horse_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3154f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the saved dataframes\n",
    "# moto_df_loaded = pd.read_parquet(output_moto_file)\n",
    "# horse_df_loaded = pd.read_parquet(output_horse_file)\n",
    "# # # assert that loaded dataframes have the same shape as original\n",
    "# assert moto_df_loaded.shape == moto_df.shape, f\"Loaded moto_df shape {moto_df_loaded.shape} does not match original {moto_df.shape}\"\n",
    "# assert horse_df_loaded.shape == horse_df.shape, f\"Loaded horse_df shape {horse_df_loaded.shape} does not match original {horse_df.shape}\"\n",
    "# # now we can name these dfs moto_df and horse_df\n",
    "# moto_df = moto_df_loaded\n",
    "# horse_df = horse_df_loaded\n",
    "# # print shapes\n",
    "# print(f\"moto_df shape: {moto_df.shape}\")\n",
    "# print(f\"horse_df shape: {horse_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "375fa817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert there are no zero columns in moto_df and horse_df\n",
    "# assert check_zero_columns(moto_df) == [], \"moto_df has zero columns\"\n",
    "# assert check_zero_columns(horse_df) == [], \"horse_df has zero columns\"\n",
    "# print(\"No zero columns in moto_df and horse_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0c64057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "# print(\"moto_df head:\")\n",
    "# display(moto_df.head())\n",
    "# print(\"horse_df head:\")\n",
    "# display(horse_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3cf01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see moto sorted by year\n",
    "# moto_sorted_by_year = moto_df.sort_values(by=\"year\")\n",
    "# # head\n",
    "# print(\"moto_df sorted by year head:\")\n",
    "# display(moto_sorted_by_year.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5ee51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's order dataframes by year and save to xlsx files\n",
    "# output_moto_xlsx = Path(\"../xlsx/latsenrom_moto_terms_counts.xlsx\")\n",
    "# output_horse_xlsx = Path(\"../xlsx/latsenrom_horse_terms_counts.xlsx\")\n",
    "# moto_df.sort_values(by=\"year\").to_excel(output_moto_xlsx, index=False)\n",
    "# horse_df.sort_values(by=\"year\").to_excel(output_horse_xlsx, index=False)\n",
    "# print(f\"Saved moto_df to {output_moto_xlsx}\")\n",
    "# print(f\"Saved horse_df to {output_horse_xlsx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1f7d2",
   "metadata": {},
   "source": [
    "## Creating relative document frequency for each term by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48000cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO now we want to create a table of relative document frequency for each term \n",
    "# relative document frequency will be calculated as follows:\n",
    "# relative_document_frequency = (term_existance_in_document_in_year / total_documents_in_year) * 100\n",
    "\n",
    "# so let's group by year use following aggregation:\n",
    "# count how many documents we have in each year\n",
    "# for each term count how many non-zero counts we have in each year\n",
    "# we will use moto_df and horse_df for that\n",
    "# # let's start with moto_df\n",
    "# def calculate_relative_document_frequency(df):\n",
    "#     # group by year and count how many documents we have in each year\n",
    "#     relative_documents_per_year = df.groupby(\"year\").size().to_frame(name='total_documents')\n",
    "\n",
    "#     # now let's add columns for each term\n",
    "#     terms = df.columns[2:]  # skip 'file_stem_short' and 'year'\n",
    "#     relative_df = pd.DataFrame(index=relative_documents_per_year.index)\n",
    "#     relative_df['year'] = relative_documents_per_year.index\n",
    "#     relative_df['total_documents'] = relative_documents_per_year['total_documents']\n",
    "#     for term in terms:\n",
    "#         # count how many non-zero counts we have in each year\n",
    "#         term_counts = df.groupby(\"year\")[term].apply(lambda x: (x > 0).sum())\n",
    "#         # calculate relative document frequency\n",
    "#         relative_df[term] = (term_counts / relative_documents_per_year['total_documents']) * 100\n",
    "#    # fill NaN values with 0\n",
    "#     relative_df.fillna(0, inplace=True)\n",
    "#     # set year as index\n",
    "#     relative_df.set_index('year', inplace=True)\n",
    "#     return relative_df\n",
    "\n",
    "    \n",
    "\n",
    "# # calculate relative document frequency for moto_df\n",
    "# moto_relative_df = calculate_relative_document_frequency(moto_df)\n",
    "# # calculate relative document frequency for horse_df\n",
    "# horse_relative_df = calculate_relative_document_frequency(horse_df)\n",
    "# # shape of relative dataframes\n",
    "# print(f\"moto_relative_df shape: {moto_relative_df.shape}\")\n",
    "# print(f\"horse_relative_df shape: {horse_relative_df.shape}\")\n",
    "# # display the first few rows of relative dataframes\n",
    "# print(\"moto_relative_df head:\")\n",
    "# display(moto_relative_df.head())\n",
    "# print(\"*\"*80)\n",
    "# print(\"horse_relative_df head:\")\n",
    "# display(horse_relative_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea18c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we want to created a simple average of all columsn after total_documents\n",
    "# def add_average_relative_frequency(df):\n",
    "#     # calculate the average of all columns except 'total_documents'\n",
    "#     df['average_relative_frequency'] = df.iloc[:, 1:].mean(axis=1)\n",
    "#     # move it to right after 'total_documents' column which is the first column\n",
    "#     cols = df.columns.tolist()\n",
    "#     cols.remove('average_relative_frequency')\n",
    "#     cols.insert(1, 'average_relative_frequency')\n",
    "#     df = df[cols]\n",
    "#     return df\n",
    "\n",
    "# # # shape of relative dataframes before adding average\n",
    "# print(f\"moto_relative_df shape before adding average: {moto_relative_df.shape}\")\n",
    "# print(f\"horse_relative_df shape before adding average: {horse_relative_df.shape}\")\n",
    "\n",
    "# # add average relative frequency to moto_relative_df\n",
    "# moto_relative_df = add_average_relative_frequency(moto_relative_df)\n",
    "# # add average relative frequency to horse_relative_df\n",
    "# horse_relative_df = add_average_relative_frequency(horse_relative_df)\n",
    "# # shape of relative dataframes after adding average\n",
    "# print(f\"moto_relative_df shape after adding average: {moto_relative_df.shape}\")\n",
    "# print(f\"horse_relative_df shape after adding average: {horse_relative_df.shape}\")\n",
    "\n",
    "# # display the first few rows of relative dataframes after adding average\n",
    "# print(\"moto_relative_df head after adding average:\")\n",
    "# display(moto_relative_df.head())\n",
    "# print(\"*\" * 80)\n",
    "# print(\"horse_relative_df head after adding average:\")\n",
    "# display(horse_relative_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b4b59",
   "metadata": {},
   "source": [
    "## Saving and Loading relative document frequency data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "415e50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's save both relative dataframes to parquet files\n",
    "# output_moto_relative_file = Path(\"../parquet/latsenrom_moto_terms_relative_counts.parquet\")\n",
    "# output_horse_relative_file = Path(\"../parquet/latsenrom_horse_terms_relative_counts.parquet\")\n",
    "# moto_relative_df.to_parquet(output_moto_relative_file)\n",
    "# horse_relative_df.to_parquet(output_horse_relative_file)\n",
    "# print(f\"Saved moto_relative_df to {output_moto_relative_file}\")\n",
    "# print(f\"Saved horse_relative_df to {output_horse_relative_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "590bd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the saved relative dataframes\n",
    "# moto_relative_df_loaded = pd.read_parquet(output_moto_relative_file)\n",
    "# horse_relative_df_loaded = pd.read_parquet(output_horse_relative_file)\n",
    "# # assert that loaded dataframes have the same shape as original\n",
    "# assert moto_relative_df_loaded.shape == moto_relative_df.shape, \\\n",
    "#     f\"Loaded moto_relative_df shape {moto_relative_df_loaded.shape} does not match original {moto_relative_df.shape}\"\n",
    "# assert horse_relative_df_loaded.shape == horse_relative_df.shape, \\\n",
    "#     f\"Loaded horse_relative_df shape {horse_relative_df_loaded.shape} does not match original {horse_relative_df.shape}\"\n",
    "# print(\"Loaded relative dataframes have the same shape as original\")\n",
    "# # now we can name these dfs moto_relative_df and horse_relative_df\n",
    "# moto_relative_df = moto_relative_df_loaded\n",
    "# horse_relative_df = horse_relative_df_loaded\n",
    "# # let's round to 4 decimal places\n",
    "# moto_relative_df = moto_relative_df.round(4)\n",
    "# horse_relative_df = horse_relative_df.round(4)\n",
    "# # shape of relative dataframes\n",
    "# print(f\"moto_relative_df shape: {moto_relative_df.shape}\")\n",
    "# print(f\"horse_relative_df shape: {horse_relative_df.shape}\")\n",
    "# # display the first few rows of relative dataframes\n",
    "# print(\"moto_relative_df head:\")\n",
    "# display(moto_relative_df.head())\n",
    "# print(\"*\" * 80)\n",
    "# print(\"horse_relative_df head:\")\n",
    "# display(horse_relative_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71e00bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # let's save to excel files as well\n",
    "# output_moto_relative_xlsx = Path(\"../xlsx/latsenrom_moto_terms_relative_counts.xlsx\")\n",
    "# output_horse_relative_xlsx = Path(\"../xlsx/latsenrom_horse_terms_relative_counts.xlsx\")\n",
    "# # before saving to excel let's round to 4 decimal places\n",
    "# moto_relative_df = moto_relative_df.round(4)\n",
    "# horse_relative_df = horse_relative_df.round(4)\n",
    "# moto_relative_df.to_excel(output_moto_relative_xlsx)\n",
    "# horse_relative_df.to_excel(output_horse_relative_xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3addc",
   "metadata": {},
   "source": [
    "## Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42de77b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date and time: 2025-05-29 12:04:53.954030\n",
      "Loaded avg_relative_df from ..\\parquet\\latsenrom_average_relative_moto_horse_frequency.parquet successfully.\n",
      "avg_relative_df shape: (44, 3)\n",
      "avg_relative_df head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>moto_average</th>\n",
       "      <th>horse_average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>1879</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.183824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>1890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>1891</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.137255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>1892</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.191176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>1893</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.073529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  moto_average  horse_average\n",
       "year                                   \n",
       "1879  1879      0.022472       0.183824\n",
       "1890  1890      0.000000       0.073529\n",
       "1891  1891      0.018727       0.137255\n",
       "1892  1892      0.011236       0.191176\n",
       "1893  1893      0.011236       0.073529"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_relative_df tail:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>moto_average</th>\n",
       "      <th>horse_average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>1936</td>\n",
       "      <td>0.062422</td>\n",
       "      <td>0.110458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>1937</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>0.122004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>1938</td>\n",
       "      <td>0.054307</td>\n",
       "      <td>0.119281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1939</td>\n",
       "      <td>0.074906</td>\n",
       "      <td>0.100763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>1940</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>0.089154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  moto_average  horse_average\n",
       "year                                   \n",
       "1936  1936      0.062422       0.110458\n",
       "1937  1937      0.056180       0.122004\n",
       "1938  1938      0.054307       0.119281\n",
       "1939  1939      0.074906       0.100763\n",
       "1940  1940      0.073736       0.089154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's simply visualize both moto and horse average_relative_frequency columns as a line chart in the same graph\n",
    "# we will use plotly express for first attempt\n",
    "# we already imported plotly express as px\n",
    "# let's create a new dataframe with year, moto average and horse average\n",
    "# def create_average_relative_frequency_df(moto_df, horse_df, no_percentage=True):\n",
    "#     # create a new dataframe with year, moto average and horse average\n",
    "#     avg_df = pd.DataFrame({\n",
    "#         'year': moto_df.index,\n",
    "#         'moto_average': moto_df['average_relative_frequency'],\n",
    "#         'horse_average': horse_df['average_relative_frequency']\n",
    "#     })\n",
    "#     if no_percentage:\n",
    "#         # convert to relative frequency by dividing by 100\n",
    "#         avg_df['moto_average'] /= 100\n",
    "#         avg_df['horse_average'] /= 100\n",
    "#     return avg_df\n",
    "\n",
    "# create average relative frequency dataframe\n",
    "# avg_relative_df = create_average_relative_frequency_df(moto_relative_df, horse_relative_df)\n",
    "# # save to parquet file\n",
    "# output_avg_relative_file = Path(\"../parquet/latsenrom_average_relative_moto_horse_frequency.parquet\")\n",
    "# avg_relative_df.to_parquet(output_avg_relative_file)\n",
    "# print(f\"Saved avg_relative_df to {output_avg_relative_file}\")\n",
    "# load the saved average relative frequency dataframe\n",
    "output_avg_relative_file = Path(\"../parquet/latsenrom_average_relative_moto_horse_frequency.parquet\")\n",
    "avg_relative_df = pd.read_parquet(output_avg_relative_file)\n",
    "print(f\"Today's date and time: {datetime.now()}\")\n",
    "print(f\"Loaded avg_relative_df from {output_avg_relative_file} successfully.\")\n",
    "# shape of avg_relative_df\n",
    "print(f\"avg_relative_df shape: {avg_relative_df.shape}\")\n",
    "# display the first few rows of avg_relative_df\n",
    "print(\"avg_relative_df head:\")\n",
    "display(avg_relative_df.head())\n",
    "# tail\n",
    "print(\"avg_relative_df tail:\")\n",
    "display(avg_relative_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a6faea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moto_color: rgb(0, 61, 165)\n",
      "horse_color: rgb(255, 194, 90)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=moto_average<br>Year=%{x}<br>Average Relative Document Frequency (%)=%{y}<extra></extra>",
         "legendgroup": "moto_average",
         "line": {
          "color": "rgb(0, 61, 165)",
          "dash": "solid",
          "width": 4
         },
         "marker": {
          "size": 12,
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "Motorized",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1879,
          1890,
          1891,
          1892,
          1893,
          1895,
          1899,
          1900,
          1901,
          1902,
          1903,
          1904,
          1905,
          1907,
          1908,
          1909,
          1910,
          1911,
          1912,
          1913,
          1914,
          1915,
          1919,
          1920,
          1921,
          1922,
          1923,
          1924,
          1925,
          1926,
          1927,
          1928,
          1929,
          1930,
          1931,
          1932,
          1933,
          1934,
          1935,
          1936,
          1937,
          1938,
          1939,
          1940
         ],
         "xaxis": "x",
         "y": [
          0.022472,
          0,
          0.018727,
          0.011236,
          0.011236,
          0.037453,
          0.067416,
          0.022472,
          0.044944,
          0.011236,
          0.011236,
          0.022472,
          0.033708,
          0.022472,
          0.014981,
          0.008427,
          0.02809,
          0.029963000000000004,
          0.046816,
          0.067416,
          0.016854,
          0,
          0.044944,
          0.050561999999999996,
          0.026966,
          0.054931,
          0.033708,
          0.043446,
          0.036918,
          0.040317,
          0.054073,
          0.053536,
          0.059484,
          0.055645,
          0.062531,
          0.074157,
          0.07397000000000001,
          0.061502,
          0.053994999999999994,
          0.062422000000000005,
          0.05618,
          0.054307,
          0.074906,
          0.073736
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=horse_average<br>Year=%{x}<br>Average Relative Document Frequency (%)=%{y}<extra></extra>",
         "legendgroup": "horse_average",
         "line": {
          "color": "rgb(255, 194, 90)",
          "dash": "solid",
          "width": 4
         },
         "marker": {
          "size": 12,
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "Horse Drawn",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1879,
          1890,
          1891,
          1892,
          1893,
          1895,
          1899,
          1900,
          1901,
          1902,
          1903,
          1904,
          1905,
          1907,
          1908,
          1909,
          1910,
          1911,
          1912,
          1913,
          1914,
          1915,
          1919,
          1920,
          1921,
          1922,
          1923,
          1924,
          1925,
          1926,
          1927,
          1928,
          1929,
          1930,
          1931,
          1932,
          1933,
          1934,
          1935,
          1936,
          1937,
          1938,
          1939,
          1940
         ],
         "xaxis": "x",
         "y": [
          0.18382400000000002,
          0.073529,
          0.13725500000000002,
          0.19117599999999998,
          0.073529,
          0.107843,
          0.220588,
          0.117647,
          0.235294,
          0.154412,
          0.066176,
          0.13725500000000002,
          0.125,
          0.06862700000000001,
          0.039216,
          0.066176,
          0.08088200000000001,
          0.107843,
          0.129902,
          0.198529,
          0.125,
          0.029411999999999997,
          0.117647,
          0.143382,
          0.09313700000000001,
          0.150327,
          0.09873900000000001,
          0.09313700000000001,
          0.086134,
          0.120242,
          0.113971,
          0.12197200000000001,
          0.09688599999999999,
          0.094538,
          0.09462899999999999,
          0.102941,
          0.126838,
          0.10139300000000001,
          0.09109500000000001,
          0.110458,
          0.122004,
          0.11928100000000001,
          0.10076299999999999,
          0.089154
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "font": {
         "size": 28
        },
        "height": 900,
        "legend": {
         "orientation": "h",
         "title": {},
         "tracegroupgap": 0,
         "traceorder": "normal",
         "x": 0,
         "y": 1.08
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 28
         },
         "x": 0.5
        },
        "width": 2470,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Average Relative Document Frequency"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now let's plot this using plotly express\n",
    "moto_color = \"rgb(0, 61, 165)\" # Pantone 293\n",
    "horse_color = \"rgb(255, 194, 90)\" # complimentary color to Pantone 293\n",
    "scale = 2\n",
    "width = 1235 * scale\n",
    "height = 450 * scale\n",
    "font_size = 18 * scale\n",
    "line_width = 2 * scale\n",
    "print(f\"moto_color: {moto_color}\")\n",
    "print(f\"horse_color: {horse_color}\")\n",
    "fig = px.line(avg_relative_df, x='year', y=['moto_average', 'horse_average'],\n",
    "              labels={'value': 'Average Relative Document Frequency (%)', 'year': 'Year'},\n",
    "              title='Average Relative Document Frequency of Moto and Horse Terms Over Years',\n",
    "              markers=True)\n",
    "# update colors\n",
    "fig.update_traces(line=dict(width=line_width))\n",
    "# update markers\n",
    "fig.update_traces(marker=dict(size=line_width*3, symbol='circle'))\n",
    "fig.update_traces(selector=dict(name='moto_average'), line=dict(color=moto_color), name='Motorized')\n",
    "fig.update_traces(selector=dict(name='horse_average'), line=dict(color=horse_color), name='Horse Drawn')\n",
    "# show the figure\n",
    "# hide title\n",
    "\n",
    "fig.update_layout(title_text=None,\n",
    "                  title_x=0.5,  # center the title\n",
    "                  title_font=dict(size=font_size),\n",
    "                  xaxis_title='Year',\n",
    "                  yaxis_title='Average Relative Document Frequency',\n",
    "                #   legend_title_text='Term Type',\n",
    "            # hide legend title\n",
    "                    legend_title=None,\n",
    "                    width=width,\n",
    "                    height=height,\n",
    "                  legend=dict(x=0.00, y=1+0.16/scale, traceorder=\"normal\", orientation=\"h\"))\n",
    "# update font size for all text\n",
    "fig.update_layout(font=dict(size=font_size))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
