{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Responses of LLM to prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2025-02-27 21:05:04.367645\n",
      "Python version: 3.12.7 (tags/v3.12.7:0b05ead, Oct  1 2024, 03:06:41) [MSC v.1941 64 bit (AMD64)]\n",
      "Requests version: 2.32.3\n",
      "Pandas version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "# first we need to import the basic libraries\n",
    "# date\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "print(f\"Date: {now}\")\n",
    "# python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "from pathlib import Path\n",
    "import json\n",
    "# import time for delay\n",
    "import time\n",
    "import requests\n",
    "# print version\n",
    "print(f\"Requests version: {requests.__version__}\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder: ..\\data\\responses\n",
      "Data folder exists: True\n",
      "Data folder is dir: True\n",
      "Subfolders:\n",
      "..\\data\\responses\\2025_01_28_gemini_2_experimental\n",
      "..\\data\\responses\\2025_01_29_google_gemini-flash-1.5-8b_no_terms\n",
      "..\\data\\responses\\2025_01_29_google_gemini-flash-1.5-8b_with_terms\n",
      "..\\data\\responses\\2025_02_04_google_gemini-flash-1.5-8b_with_terms\n",
      "..\\data\\responses\\2025_02_26_google_gemini-flash-1.5_land_prompt_1\n",
      "..\\data\\responses\\2025_02_26_google_gemini-flash-1.5_land_prompt_2\n",
      "..\\data\\responses\\2025_02_26_openai_gpt-4o-2024-11-20_land_prompt\n",
      "..\\data\\responses\\2025_02_26_openai_gpt-4o-2024-11-20_land_prompt_2\n",
      "..\\data\\responses\\2025_02_27_google_gemini-2.0-flash-001_land_prompt\n",
      "..\\data\\responses\\2025_02_27_google_gemini-2.0-flash-001_land_prompt_2\n",
      "..\\data\\responses\\2025_02_27_google_gemini-flash-1.5_land_prompt\n",
      "..\\data\\responses\\2025_02_27_google_gemini-flash-1.5_maritime_prompt\n",
      "..\\data\\responses\\temp_responses_2025_02_26\n"
     ]
    }
   ],
   "source": [
    "# let's see what folders are in our ../data/responses folder\n",
    "data_folder = Path(\"../data/responses\")\n",
    "print(f\"Data folder: {data_folder}\")\n",
    "print(f\"Data folder exists: {data_folder.exists()}\")\n",
    "print(f\"Data folder is dir: {data_folder.is_dir()}\")\n",
    "# let's see what subfolders are in our data folder\n",
    "subfolders = [f for f in data_folder.iterdir() if f.is_dir()]\n",
    "print(f\"Subfolders:\")\n",
    "for subfolder in subfolders:\n",
    "    print(subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate openai responses\n",
    "\n",
    "OpenAI prompts required us to break down files into smaller chunks, now we need to consolidate them back into a single file.\n",
    "\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI folders:\n",
      "..\\data\\responses\\2025_02_26_openai_gpt-4o-2024-11-20_land_prompt\n",
      "..\\data\\responses\\2025_02_26_openai_gpt-4o-2024-11-20_land_prompt_2\n"
     ]
    }
   ],
   "source": [
    "# subfolders that contain openai in their name\n",
    "openai_folders = [f for f in data_folder.iterdir() if f.is_dir() and \"openai\" in f.name]\n",
    "print(f\"OpenAI folders:\")\n",
    "for openai_folder in openai_folders:\n",
    "    print(openai_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI files:\n",
      "AustA_KaspG_948026: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/AustA_KaspG_948026_0.txt')]\n",
      "AustA_Puisk_1047362: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/AustA_Puisk_1047362_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/AustA_Puisk_1047362_1.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/AustA_Puisk_1047362_2.txt')]\n",
      "FimbK_KadNa_1049450: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/FimbK_KadNa_1049450_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/FimbK_KadNa_1049450_1.txt')]\n",
      "FimbK_TiltP_1049479: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/FimbK_TiltP_1049479_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/FimbK_TiltP_1049479_1.txt')]\n",
      "GulbA_Gaidi_1350352: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/GulbA_Gaidi_1350352_0.txt')]\n",
      "GulbA_JaunV_1053680: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/GulbA_JaunV_1053680_0.txt')]\n",
      "LaciV_AtbrZ_1051755: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LaciV_AtbrZ_1051755_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LaciV_AtbrZ_1051755_1.txt')]\n",
      "LaciV_PulaE_1053689: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LaciV_PulaE_1053689_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LaciV_PulaE_1053689_1.txt')]\n",
      "LapiK_DodaU_1046848: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LapiK_DodaU_1046848_0.txt')]\n",
      "LapiK_ManaD_1051717: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LapiK_ManaD_1051717_0.txt')]\n",
      "LesiVi_LiktR_1051787: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LesiVi_LiktR_1051787_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LesiVi_LiktR_1051787_1.txt')]\n",
      "LesiVi_Uzvar_1350343: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LesiVi_Uzvar_1350343_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LesiVi_Uzvar_1350343_1.txt')]\n",
      "NiedAi_CilvA_1025449: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/NiedAi_CilvA_1025449_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/NiedAi_CilvA_1025449_1.txt')]\n",
      "NiedAi_Salna_1049440: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/NiedAi_Salna_1049440_0.txt')]\n",
      "PaulM_SirdP_1049495: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/PaulM_SirdP_1049495_0.txt')]\n",
      "PaulM_VienV_1049499: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/PaulM_VienV_1049499_0.txt')]\n",
      "RoziP_DivaS_1053490: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/RoziP_DivaS_1053490_0.txt')]\n",
      "RoziP_UgunC_1046826: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/RoziP_UgunC_1046826_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/RoziP_UgunC_1046826_1.txt')]\n",
      "SartJ_Pagar_1047279: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/SartJ_Pagar_1047279_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/SartJ_Pagar_1047279_1.txt')]\n",
      "SartJ_Zieda_1051763: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/SartJ_Zieda_1051763_0.txt')]\n"
     ]
    }
   ],
   "source": [
    "# we want to create a function that given a subfolder will return a dictionary \n",
    "# keys will be first three parts of file name when split by _\n",
    "# values will be actual file names\n",
    "def get_files(subfolder):\n",
    "    files = {}\n",
    "    for file in subfolder.iterdir():\n",
    "        if file.is_file():\n",
    "            parts = file.name.split(\"_\")\n",
    "            key = \"_\".join(parts[:3])\n",
    "            if key in files:\n",
    "                files[key].append(file)\n",
    "            else:\n",
    "                files[key] = [file]\n",
    "    return files\n",
    "\n",
    "# let's run this function on one of the openai folders\n",
    "openai_files = get_files(openai_folders[0])\n",
    "print(f\"OpenAI files:\")\n",
    "for key, value in openai_files.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025_02_26_openai_gpt-4o-2024-11-20_land_prompt: 20\n",
      "2025_02_26_openai_gpt-4o-2024-11-20_land_prompt_2: 20\n"
     ]
    }
   ],
   "source": [
    "# let's run get_files on all openai folders\n",
    "# the key will be folder name and values will be dictionaries returned by get_files\n",
    "openai_files = {}\n",
    "for openai_folder in openai_folders:\n",
    "    openai_files[openai_folder.name] = get_files(openai_folder)\n",
    "\n",
    "# how many files are in each folder\n",
    "for key, value in openai_files.items():\n",
    "    print(f\"{key}: {len(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's write a function that given a file name and file list and new_subfolder will write consolidated file to new_subfolder\n",
    "# logic is as follows:\n",
    "# we want to read all content of files in file list up to empty line\n",
    "# we want to write all this content to new file in new_subfolder\n",
    "# then we want to separately read all lines starting with line that starts with \"System prompt:\"\n",
    "# we want to write this content only once to new file in new_subfolder\n",
    "# we want use utf-8 encoding\n",
    "def consolidate_files(file_name, file_list, new_subfolder):\n",
    "    # create new subfolder if it does not exist\n",
    "    new_subfolder.mkdir(parents=True, exist_ok=True)\n",
    "    with open(new_subfolder / f\"{file_name}.txt\", \"w\", encoding=\"utf-8\") as new_file:\n",
    "        system_prompts = []\n",
    "        for file in file_list:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as old_file:\n",
    "                text = old_file.read()\n",
    "                # let's split on \"System prompt:\"\n",
    "                parts = text.split(\"System prompt:\")\n",
    "                # let's write first part\n",
    "                new_file.write(parts[0].strip()+\"\\n\")\n",
    "                # append second part to system_prompts\n",
    "                system_prompts.append(parts[1])\n",
    "        # let's write system prompts only once\n",
    "        # first check if system prompts are identical\n",
    "        if len(set(system_prompts)) == 1:\n",
    "            new_file.write(\"\\nSystem prompt:\" + system_prompts[0])\n",
    "        else:\n",
    "            for system_prompt in system_prompts:\n",
    "                new_file.write(\"System prompt:\\n\" + system_prompt)\n",
    "\n",
    "# test it on second key of openai_files\n",
    "# we will create a new subfolder in the data respones folder\n",
    "# new_subfolder = data_folder / \"consolidated\"\n",
    "# consolidate_files(list(openai_files.keys())[1], openai_files[list(openai_files.keys())[1]], new_subfolder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's write a function that will consolidate all files in all openai folders\n",
    "# we will use consolidate_files function\n",
    "# new subfolder will be in data folder\n",
    "# it will be called consolidated_ + key of openai_files\n",
    "def consolidate_all_files(openai_files, data_folder):\n",
    "    for key, value in openai_files.items():\n",
    "        new_subfolder = data_folder / (\"consolidated_\" + key)\n",
    "        # value is a dictionary that contains keys that are first three parts of file name and values that are lists of files\n",
    "        for key2, value2 in value.items():\n",
    "            consolidate_files(key2, value2, new_subfolder)\n",
    "\n",
    "# let's run this function\n",
    "consolidate_all_files(openai_files, data_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
