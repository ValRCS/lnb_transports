{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Responses of LLM to prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2025-02-27 21:05:04.367645\n",
      "Python version: 3.12.7 (tags/v3.12.7:0b05ead, Oct  1 2024, 03:06:41) [MSC v.1941 64 bit (AMD64)]\n",
      "Requests version: 2.32.3\n",
      "Pandas version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "# first we need to import the basic libraries\n",
    "# date\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "print(f\"Date: {now}\")\n",
    "# python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "from pathlib import Path\n",
    "import json\n",
    "# import time for delay\n",
    "import time\n",
    "import requests\n",
    "# print version\n",
    "print(f\"Requests version: {requests.__version__}\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder: ..\\data\\responses\n",
      "Data folder exists: True\n",
      "Data folder is dir: True\n",
      "Subfolders:\n",
      "..\\data\\responses\\2025_01_28_gemini_2_experimental\n",
      "..\\data\\responses\\2025_01_29_google_gemini-flash-1.5-8b_no_terms\n",
      "..\\data\\responses\\2025_01_29_google_gemini-flash-1.5-8b_with_terms\n",
      "..\\data\\responses\\2025_02_04_google_gemini-flash-1.5-8b_with_terms\n",
      "..\\data\\responses\\2025_02_26_google_gemini-flash-1.5_land_prompt_1\n",
      "..\\data\\responses\\2025_02_26_google_gemini-flash-1.5_land_prompt_2\n",
      "..\\data\\responses\\2025_02_26_openai_gpt-4o-2024-11-20_land_prompt\n",
      "..\\data\\responses\\2025_02_26_openai_gpt-4o-2024-11-20_land_prompt_2\n",
      "..\\data\\responses\\2025_02_27_google_gemini-2.0-flash-001_land_prompt\n",
      "..\\data\\responses\\2025_02_27_google_gemini-2.0-flash-001_land_prompt_2\n",
      "..\\data\\responses\\2025_02_27_google_gemini-flash-1.5_land_prompt\n",
      "..\\data\\responses\\2025_02_27_google_gemini-flash-1.5_maritime_prompt\n",
      "..\\data\\responses\\temp_responses_2025_02_26\n"
     ]
    }
   ],
   "source": [
    "# let's see what folders are in our ../data/responses folder\n",
    "data_folder = Path(\"../data/responses\")\n",
    "print(f\"Data folder: {data_folder}\")\n",
    "print(f\"Data folder exists: {data_folder.exists()}\")\n",
    "print(f\"Data folder is dir: {data_folder.is_dir()}\")\n",
    "# let's see what subfolders are in our data folder\n",
    "subfolders = [f for f in data_folder.iterdir() if f.is_dir()]\n",
    "print(f\"Subfolders:\")\n",
    "for subfolder in subfolders:\n",
    "    print(subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate openai responses\n",
    "\n",
    "OpenAI prompts required us to break down files into smaller chunks, now we need to consolidate them back into a single file.\n",
    "\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI folders:\n",
      "..\\data\\responses\\2025_02_26_openai_gpt-4o-2024-11-20_land_prompt\n",
      "..\\data\\responses\\2025_02_26_openai_gpt-4o-2024-11-20_land_prompt_2\n"
     ]
    }
   ],
   "source": [
    "# subfolders that contain openai in their name\n",
    "openai_folders = [f for f in data_folder.iterdir() if f.is_dir() and \"openai\" in f.name]\n",
    "print(f\"OpenAI folders:\")\n",
    "for openai_folder in openai_folders:\n",
    "    print(openai_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI files:\n",
      "AustA_KaspG_948026: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/AustA_KaspG_948026_0.txt')]\n",
      "AustA_Puisk_1047362: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/AustA_Puisk_1047362_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/AustA_Puisk_1047362_1.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/AustA_Puisk_1047362_2.txt')]\n",
      "FimbK_KadNa_1049450: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/FimbK_KadNa_1049450_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/FimbK_KadNa_1049450_1.txt')]\n",
      "FimbK_TiltP_1049479: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/FimbK_TiltP_1049479_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/FimbK_TiltP_1049479_1.txt')]\n",
      "GulbA_Gaidi_1350352: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/GulbA_Gaidi_1350352_0.txt')]\n",
      "GulbA_JaunV_1053680: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/GulbA_JaunV_1053680_0.txt')]\n",
      "LaciV_AtbrZ_1051755: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LaciV_AtbrZ_1051755_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LaciV_AtbrZ_1051755_1.txt')]\n",
      "LaciV_PulaE_1053689: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LaciV_PulaE_1053689_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LaciV_PulaE_1053689_1.txt')]\n",
      "LapiK_DodaU_1046848: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LapiK_DodaU_1046848_0.txt')]\n",
      "LapiK_ManaD_1051717: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LapiK_ManaD_1051717_0.txt')]\n",
      "LesiVi_LiktR_1051787: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LesiVi_LiktR_1051787_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LesiVi_LiktR_1051787_1.txt')]\n",
      "LesiVi_Uzvar_1350343: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LesiVi_Uzvar_1350343_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/LesiVi_Uzvar_1350343_1.txt')]\n",
      "NiedAi_CilvA_1025449: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/NiedAi_CilvA_1025449_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/NiedAi_CilvA_1025449_1.txt')]\n",
      "NiedAi_Salna_1049440: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/NiedAi_Salna_1049440_0.txt')]\n",
      "PaulM_SirdP_1049495: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/PaulM_SirdP_1049495_0.txt')]\n",
      "PaulM_VienV_1049499: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/PaulM_VienV_1049499_0.txt')]\n",
      "RoziP_DivaS_1053490: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/RoziP_DivaS_1053490_0.txt')]\n",
      "RoziP_UgunC_1046826: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/RoziP_UgunC_1046826_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/RoziP_UgunC_1046826_1.txt')]\n",
      "SartJ_Pagar_1047279: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/SartJ_Pagar_1047279_0.txt'), WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/SartJ_Pagar_1047279_1.txt')]\n",
      "SartJ_Zieda_1051763: [WindowsPath('../data/responses/2025_02_26_openai_gpt-4o-2024-11-20_land_prompt/SartJ_Zieda_1051763_0.txt')]\n"
     ]
    }
   ],
   "source": [
    "# we want to create a function that given a subfolder will return a dictionary \n",
    "# keys will be first three parts of file name when split by _\n",
    "# values will be actual file names\n",
    "def get_files(subfolder):\n",
    "    files = {}\n",
    "    for file in subfolder.iterdir():\n",
    "        if file.is_file():\n",
    "            parts = file.name.split(\"_\")\n",
    "            key = \"_\".join(parts[:3])\n",
    "            if key in files:\n",
    "                files[key].append(file)\n",
    "            else:\n",
    "                files[key] = [file]\n",
    "    return files\n",
    "\n",
    "# let's run this function on one of the openai folders\n",
    "openai_files = get_files(openai_folders[0])\n",
    "print(f\"OpenAI files:\")\n",
    "for key, value in openai_files.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025_02_26_openai_gpt-4o-2024-11-20_land_prompt: 20\n",
      "2025_02_26_openai_gpt-4o-2024-11-20_land_prompt_2: 20\n"
     ]
    }
   ],
   "source": [
    "# let's run get_files on all openai folders\n",
    "# the key will be folder name and values will be dictionaries returned by get_files\n",
    "openai_files = {}\n",
    "for openai_folder in openai_folders:\n",
    "    openai_files[openai_folder.name] = get_files(openai_folder)\n",
    "\n",
    "# how many files are in each folder\n",
    "for key, value in openai_files.items():\n",
    "    print(f\"{key}: {len(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's write a function that given a file name and file list and new_subfolder will write consolidated file to new_subfolder\n",
    "# logic is as follows:\n",
    "# we want to read all content of files in file list up to empty line\n",
    "# we want to write all this content to new file in new_subfolder\n",
    "# then we want to separately read all lines starting with line that starts with \"System prompt:\"\n",
    "# we want to write this content only once to new file in new_subfolder\n",
    "# we want use utf-8 encoding\n",
    "def consolidate_files(file_name, file_list, new_subfolder):\n",
    "    # create new subfolder if it does not exist\n",
    "    new_subfolder.mkdir(parents=True, exist_ok=True)\n",
    "    with open(new_subfolder / f\"{file_name}.txt\", \"w\", encoding=\"utf-8\") as new_file:\n",
    "        system_prompts = []\n",
    "        for file in file_list:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as old_file:\n",
    "                text = old_file.read()\n",
    "                # let's split on \"System prompt:\"\n",
    "                parts = text.split(\"System prompt:\")\n",
    "                # let's write first part\n",
    "                new_file.write(parts[0].strip()+\"\\n\")\n",
    "                # append second part to system_prompts\n",
    "                system_prompts.append(parts[1])\n",
    "        # let's write system prompts only once\n",
    "        # first check if system prompts are identical\n",
    "        if len(set(system_prompts)) == 1:\n",
    "            new_file.write(\"\\nSystem prompt:\" + system_prompts[0])\n",
    "        else:\n",
    "            for system_prompt in system_prompts:\n",
    "                new_file.write(\"System prompt:\\n\" + system_prompt)\n",
    "\n",
    "# test it on second key of openai_files\n",
    "# we will create a new subfolder in the data respones folder\n",
    "# new_subfolder = data_folder / \"consolidated\"\n",
    "# consolidate_files(list(openai_files.keys())[1], openai_files[list(openai_files.keys())[1]], new_subfolder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's write a function that will consolidate all files in all openai folders\n",
    "# we will use consolidate_files function\n",
    "# new subfolder will be in data folder\n",
    "# it will be called consolidated_ + key of openai_files\n",
    "def consolidate_all_files(openai_files, data_folder):\n",
    "    for key, value in openai_files.items():\n",
    "        new_subfolder = data_folder / (\"consolidated_\" + key)\n",
    "        # value is a dictionary that contains keys that are first three parts of file name and values that are lists of files\n",
    "        for key2, value2 in value.items():\n",
    "            consolidate_files(key2, value2, new_subfolder)\n",
    "\n",
    "# let's run this function\n",
    "consolidate_all_files(openai_files, data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the subfolders for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders to analyze:\n",
      "..\\data\\responses\\consolidated_2025_02_26_openai_gpt-4o-2024-11-20_land_prompt\n",
      "..\\data\\responses\\consolidated_2025_02_26_openai_gpt-4o-2024-11-20_land_prompt_2\n",
      "..\\data\\responses\\2025_02_26_google_gemini-flash-1.5_land_prompt_1\n",
      "..\\data\\responses\\2025_02_26_google_gemini-flash-1.5_land_prompt_2\n",
      "..\\data\\responses\\2025_02_27_google_gemini-2.0-flash-001_land_prompt\n",
      "..\\data\\responses\\2025_02_27_google_gemini-2.0-flash-001_land_prompt_2\n"
     ]
    }
   ],
   "source": [
    "# now we want to get all folders that we want to analyze\n",
    "# they are in data_folder \n",
    "# we want those that start with consolidated_2025_02_26 or consolidated_2025_02_27\n",
    "# we also want those that start with 2025_02_26 or 2025_02_27 and also contain words land_prompt\n",
    "# these will be the folders that we want to analyze\n",
    "folders_to_analyze = [f for f in data_folder.iterdir() if f.is_dir() and (f.name.startswith(\"consolidated_2025_02_26\") or f.name.startswith(\"consolidated_2025_02_27\"))]\n",
    "folders_to_analyze += [f for f in data_folder.iterdir() if f.is_dir() and (f.name.startswith(\"2025_02_26\") or f.name.startswith(\"2025_02_27\")) and \"land_prompt\" in f.name]\n",
    "print(f\"Folders to analyze:\")\n",
    "for folder in folders_to_analyze:\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Plaintext into  memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 458/458 [00:08<00:00, 57.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts: 458\n",
      "Total characters: 191069647\n",
      "Key for smallest text: VentA_DepuT_1293527\n",
      "Number of characters in smallest text: 18648\n",
      "Key for largest text: DeglA_LabaF_1053655\n",
      "Number of characters in largest text: 2375090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Plaintexts are in another repo - private in our parent folder\n",
    "# let's list all text files in data/docs folder\n",
    "# data_folder = Path(\"../data/docs\")\n",
    "# data_folder = Path(\"../../lnb_lat_sen_rom_releases/lat_sen_rom_2025_01_28\")\n",
    "data_folder = Path(\"../../lnb_lat_sen_rom_releases/lat_sen_rom_2025_02_04\")\n",
    "# assert folder exists\n",
    "assert data_folder.exists(), f\"Folder {data_folder} does not exist\"\n",
    "                   \n",
    "# list all files\n",
    "files = list(data_folder.glob(\"*.txt\"))\n",
    "# print all files\n",
    "# how many files do we have?\n",
    "print(f\"Number of files: {len(files)}\")\n",
    "# let's load the files into a dictionary with filename stem as key and text as value\n",
    "# remember to decode the text as utf-8\n",
    "texts = {}\n",
    "for file in tqdm(files):\n",
    "  with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "    texts[file.stem] = f.read()\n",
    "# how many texts do we have?\n",
    "print(f\"Number of texts: {len(texts)}\")\n",
    "# how many characters do we have in total?\n",
    "total_chars = sum([len(text) for text in texts.values()])\n",
    "print(f\"Total characters: {total_chars}\")\n",
    "# what is the smallest text?\n",
    "min_text = min(texts, key=lambda x: len(texts[x]))\n",
    "print(f\"Key for smallest text: {min_text}\")\n",
    "# how many characters does the smallest text have?\n",
    "min_chars = len(texts[min_text])\n",
    "print(f\"Number of characters in smallest text: {min_chars}\")\n",
    "# what is the largest text?\n",
    "max_text = max(texts, key=lambda x: len(texts[x]))\n",
    "print(f\"Key for largest text: {max_text}\")\n",
    "# how many characters does the largest text have?\n",
    "max_chars = len(texts[max_text])\n",
    "print(f\"Number of characters in largest text: {max_chars}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are identical\n"
     ]
    }
   ],
   "source": [
    "# first let's assert that all our folders have identical file names\n",
    "# we will use the first folder as reference\n",
    "reference_files = Path(folders_to_analyze[0]).iterdir()\n",
    "reference_files = [file.name for file in reference_files]\n",
    "for folder in folders_to_analyze[1:]:\n",
    "    files = Path(folder).iterdir()\n",
    "    files = [file.name for file in files]\n",
    "    assert reference_files == files, f\"Files in {folders_to_analyze[0]} and {folder} are not identical\"\n",
    "\n",
    "print(\"All files are identical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response lines: ['zirgi', 'kamanas', 'trijjūgi', 'kropli', 'rati', 'zirgu slidas']\n"
     ]
    }
   ],
   "source": [
    "# let's write a function that given a file will extract all response lines\n",
    "# response lines are those that come before empty line\n",
    "# we will return a list of response lines\n",
    "def get_response_lines(file):\n",
    "    response_lines = []\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.strip() == \"\":\n",
    "                break\n",
    "            response_lines.append(line.strip())\n",
    "    return response_lines\n",
    "\n",
    "# test on first file in reference folder\n",
    "response_lines = get_response_lines(Path(folders_to_analyze[0]) / reference_files[0])\n",
    "print(f\"Response lines: {response_lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../data/responses/consolidated_2025_02_26_openai_gpt-4o-2024-11-20_land_prompt'),\n",
       " WindowsPath('../data/responses/consolidated_2025_02_26_openai_gpt-4o-2024-11-20_land_prompt_2'),\n",
       " WindowsPath('../data/responses/2025_02_26_google_gemini-flash-1.5_land_prompt_1'),\n",
       " WindowsPath('../data/responses/2025_02_26_google_gemini-flash-1.5_land_prompt_2'),\n",
       " WindowsPath('../data/responses/2025_02_27_google_gemini-2.0-flash-001_land_prompt'),\n",
       " WindowsPath('../data/responses/2025_02_27_google_gemini-2.0-flash-001_land_prompt_2')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders_to_analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consolidated_2025_02_26_openai_gpt-4o-2024-11-20_land_prompt</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kamanas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kropli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rati</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trijjūgi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zirgi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  consolidated_2025_02_26_openai_gpt-4o-2024-11-20_land_prompt  count\n",
       "0                                            kamanas                1\n",
       "1                                             kropli                1\n",
       "2                                               rati                2\n",
       "3                                           trijjūgi                3\n",
       "4                                              zirgi                4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's write a function that given a file and texts dictionary will return a dataframe with two columns\n",
    "# first column will be terms sorted from get_response_lines (could be duplicates)\n",
    "# second column will count of occurences of term in text from matching key in texts dictionary\n",
    "# key will be file name stem\n",
    "def get_response_df(file, texts):\n",
    "    response_lines = get_response_lines(file)\n",
    "    data = []\n",
    "    plaintext = texts.get(file.stem, \"\")\n",
    "    # our term column name will be parent folder name of file\n",
    "    term_column = file.parent.name\n",
    "    # term_column = file.stem\n",
    "    if plaintext == \"\":\n",
    "        print(f\"Plaintext not found for {file.stem}\")\n",
    "    for line in sorted(response_lines):\n",
    "        data.append({term_column: line, \"count\": plaintext.count(line)})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# test on first file in reference folder\n",
    "df = get_response_df(Path(folders_to_analyze[0]) / reference_files[0], texts)\n",
    "print(f\"Response dataframe:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AustA_KaspG_948026.txt'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consolidated_2025_02_26_openai_gpt-4o-2024-11-20_land_prompt</th>\n",
       "      <th>count</th>\n",
       "      <th>consolidated_2025_02_26_openai_gpt-4o-2024-11-20_land_prompt_2</th>\n",
       "      <th>count</th>\n",
       "      <th>2025_02_26_google_gemini-flash-1.5_land_prompt_1</th>\n",
       "      <th>count</th>\n",
       "      <th>2025_02_26_google_gemini-flash-1.5_land_prompt_2</th>\n",
       "      <th>count</th>\n",
       "      <th>2025_02_27_google_gemini-2.0-flash-001_land_prompt</th>\n",
       "      <th>count</th>\n",
       "      <th>2025_02_27_google_gemini-2.0-flash-001_land_prompt_2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kamanas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>kamanas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>auļos</td>\n",
       "      <td>1</td>\n",
       "      <td>kamanam</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dzelzsceļa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>automobiļi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kropli</td>\n",
       "      <td>1.0</td>\n",
       "      <td>krievu trijjūgi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fūrmaņu kamanas</td>\n",
       "      <td>0</td>\n",
       "      <td>ragavas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fūrmaņu kamanas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kamanām</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rati</td>\n",
       "      <td>2.0</td>\n",
       "      <td>mērnieka kājas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kamanam</td>\n",
       "      <td>1</td>\n",
       "      <td>slitas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>kamanas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pātagas</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trijjūgi</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ragavas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>kamanas</td>\n",
       "      <td>1</td>\n",
       "      <td>trijjūgiem</td>\n",
       "      <td>1.0</td>\n",
       "      <td>trijjūgi</td>\n",
       "      <td>3.0</td>\n",
       "      <td>zirgiem</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zirgi</td>\n",
       "      <td>4.0</td>\n",
       "      <td>trijjūgi</td>\n",
       "      <td>3.0</td>\n",
       "      <td>kamanās</td>\n",
       "      <td>8</td>\n",
       "      <td>vilcienu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>vezumnieku ragavas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  consolidated_2025_02_26_openai_gpt-4o-2024-11-20_land_prompt  count  \\\n",
       "0                                            kamanas              1.0   \n",
       "1                                             kropli              1.0   \n",
       "2                                               rati              2.0   \n",
       "3                                           trijjūgi              3.0   \n",
       "4                                              zirgi              4.0   \n",
       "\n",
       "  consolidated_2025_02_26_openai_gpt-4o-2024-11-20_land_prompt_2  count  \\\n",
       "0                                            kamanas                1.0   \n",
       "1                                    krievu trijjūgi                1.0   \n",
       "2                                     mērnieka kājas                0.0   \n",
       "3                                            ragavas                1.0   \n",
       "4                                           trijjūgi                3.0   \n",
       "\n",
       "  2025_02_26_google_gemini-flash-1.5_land_prompt_1  count  \\\n",
       "0                                            auļos      1   \n",
       "1                                  fūrmaņu kamanas      0   \n",
       "2                                          kamanam      1   \n",
       "3                                          kamanas      1   \n",
       "4                                          kamanās      8   \n",
       "\n",
       "  2025_02_26_google_gemini-flash-1.5_land_prompt_2  count  \\\n",
       "0                                          kamanam    1.0   \n",
       "1                                          ragavas    1.0   \n",
       "2                                           slitas    1.0   \n",
       "3                                       trijjūgiem    1.0   \n",
       "4                                         vilcienu    1.0   \n",
       "\n",
       "  2025_02_27_google_gemini-2.0-flash-001_land_prompt  count  \\\n",
       "0                                         dzelzsceļa    2.0   \n",
       "1                                    fūrmaņu kamanas    0.0   \n",
       "2                                            kamanas    1.0   \n",
       "3                                           trijjūgi    3.0   \n",
       "4                                 vezumnieku ragavas    1.0   \n",
       "\n",
       "  2025_02_27_google_gemini-2.0-flash-001_land_prompt_2  count  \n",
       "0                                         automobiļi      0.0  \n",
       "1                                            kamanām      0.0  \n",
       "2                                            pātagas      2.0  \n",
       "3                                            zirgiem      4.0  \n",
       "4                                                NaN      NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's write a function tht given a file and list of subfolders will return a combined dataframe\n",
    "# columns will obtained by horizontally concatenating dataframes obtained by get_response_df\n",
    "# index will be numerical\n",
    "def get_combined_df(file, texts, subfolders):\n",
    "    dfs = []\n",
    "    for subfolder in subfolders:\n",
    "        df = get_response_df(subfolder / file, texts)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, axis=1)\n",
    "\n",
    "# let's test it on first file in reference folder\n",
    "df = get_combined_df(reference_files[0], texts, folders_to_analyze)\n",
    "print(f\"Combined dataframe:\")\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's create a function that will create a CSV file for each file in reference folder\n",
    "# we will use get_combined_df to get the dataframe\n",
    "# we will supply target folder where we want to save the CSV files\n",
    "def create_csv_files(reference_files, texts, subfolders, target_folder, save_excel=True):\n",
    "    # create target folder if it does not exist\n",
    "    target_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for file in reference_files:\n",
    "        df = get_combined_df(file, texts, subfolders)\n",
    "        df.to_csv(target_folder / f\"{Path(file).stem}.csv\", index=False)\n",
    "        if save_excel:\n",
    "            df.to_excel(target_folder / f\"{Path(file).stem}.xlsx\", index=False)\n",
    "\n",
    "# let's test it on reference files\n",
    "# target folder will be data folder with name analysis and datetime stamp\n",
    "target_folder = Path(\"../data\") / \"analysis\" / now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "create_csv_files(reference_files, texts, folders_to_analyze, target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\..\\lnb_lat_sen_rom_releases\\lat_sen_rom_2025_02_04\\analysis\\2025_02_27_21_05_04\n"
     ]
    }
   ],
   "source": [
    "print(target_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
